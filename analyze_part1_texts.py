"""
Comprehensive Analysis of Anubhuta Jogamala Part 1 Texts

This script analyzes the extracted text files from Part 1 to understand:
- Language patterns and script characteristics
- Thematic content and medical knowledge
- Document structure and organization
- Cultural and historical context
"""

import logging
import re
from collections import Counter, defaultdict
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def analyze_part1_texts() -> None:
    """Analyze the Part 1 text files and provide comprehensive insights."""
    
    text_dir = Path('part_1_text')
    if not text_dir.exists():
        print("‚ùå Error: part_1_text directory not found!")
        return
    
    print("üîÑ Starting comprehensive analysis of Anubhuta Jogamala Part 1 texts...")
    
    # Load all text files
    texts = {}
    text_files = list(text_dir.glob("*.txt"))
    
    for file_path in sorted(text_files):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                if content and len(content) > 10:  # Filter out empty/minimal files
                    texts[file_path.name] = content
        except Exception as e:
            print(f"‚ö†Ô∏è Warning: Could not read {file_path.name}: {e}")
    
    if not texts:
        print("‚ùå No valid text files found to analyze!")
        return
    
    print(f"‚úÖ Loaded {len(texts)} text files for analysis")
    
    # Combine all text for analysis
    all_text = " ".join(texts.values())
    
    print("\n" + "="*80)
    print("üîç ANUBHUTA JOGAMALA PART 1 - COMPREHENSIVE TEXT ANALYSIS")
    print("="*80)
    
    # Basic Statistics
    print(f"\nüìä BASIC STATISTICS")
    total_chars = len(all_text)
    words = re.findall(r'\S+', all_text)
    sentences = re.split(r'[‡•§\.\!\?]', all_text)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    print(f"   ‚Ä¢ Total files analyzed: {len(texts)}")
    print(f"   ‚Ä¢ Total characters: {total_chars:,}")
    print(f"   ‚Ä¢ Total words: {len(words):,}")
    print(f"   ‚Ä¢ Total sentences: {len(sentences):,}")
    print(f"   ‚Ä¢ Average words per sentence: {len(words)/len(sentences):.1f}")
    
    # Language Analysis
    print(f"\nüî§ LANGUAGE CHARACTERISTICS")
    
    # Character analysis
    odia_chars = sum(1 for char in all_text if '\u0B00' <= char <= '\u0B7F')
    english_chars = sum(1 for char in all_text if char.isascii() and char.isalpha())
    digits = sum(1 for char in all_text if char.isdigit())
    
    print(f"   ‚Ä¢ Odia script: {odia_chars:,} ({odia_chars/total_chars*100:.1f}%)")
    print(f"   ‚Ä¢ English script: {english_chars:,} ({english_chars/total_chars*100:.1f}%)")
    print(f"   ‚Ä¢ Digits: {digits:,} ({digits/total_chars*100:.1f}%)")
    
    # Most common characters
    char_counter = Counter(all_text)
    print(f"   ‚Ä¢ Most common Odia characters:")
    odia_chars_common = [(char, count) for char, count in char_counter.most_common(50) 
                        if '\u0B00' <= char <= '\u0B7F']
    for char, count in odia_chars_common[:10]:
        print(f"     - '{char}': {count:,} times")
    
    # Medical Terminology Analysis
    print(f"\nüè• MEDICAL THEMES & TERMINOLOGY")
    
    # Common medical terms
    medical_terms = {
        '‡¨∞‡≠ã‡¨ó': 'disease/illness',
        '‡¨ö‡¨ø‡¨ï‡¨ø‡¨§‡≠ç‡¨∏‡¨æ': 'treatment',
        '‡¨î‡¨∑‡¨ß': 'medicine',
        '‡¨Ø‡≠ã‡¨ó': 'remedy/prescription',
        '‡¨™‡¨§‡≠ç‡¨∞': 'leaf',
        '‡¨∞‡¨∏': 'juice/extract',
        '‡¨™‡¨ø‡¨Ü‡¨á‡¨¨': 'to drink/consume',
        '‡¨≤‡¨ó‡¨æ‡¨á‡¨¨': 'to apply',
        '‡¨Æ‡¨ø‡¨∂‡¨æ‡¨á': 'mixing',
        '‡¨ó‡≠Å‡¨£‡≠ç‡¨°': 'powder',
        '‡¨ö‡≠Ç‡¨∞‡≠ç‡¨£‡≠ç‡¨£': 'powder/crushed',
        '‡¨ï‡¨æ‡¨¢‡¨º‡¨æ': 'decoction',
        '‡¨ò‡¨æ': 'wound',
        '‡¨¨‡≠á‡¨¶‡¨®‡¨æ': 'pain',
        '‡¨ú‡≠ç‡¨¨‡¨∞': 'fever',
        '‡¨ï‡¨æ‡¨∂': 'cough',
        '‡¨™‡≠á‡¨ü': 'stomach',
        '‡¨Æ‡≠Å‡¨£‡≠ç‡¨°': 'head'
    }
    
    term_freq = {}
    for term, meaning in medical_terms.items():
        count = all_text.count(term)
        if count > 0:
            term_freq[f"{term} ({meaning})"] = count
    
    print(f"   ‚Ä¢ Medical terminology frequency:")
    for term, count in sorted(term_freq.items(), key=lambda x: x[1], reverse=True)[:10]:
        print(f"     - {term}: {count} times")
    
    # Plant/Herb Analysis
    print(f"\nüåø PLANT & HERB REFERENCES")
    
    # Extract plant names (words with common suffixes)
    plant_patterns = [r'\w+‡¨™‡¨§‡≠ç‡¨∞', r'\w+‡¨Æ‡≠Ç‡¨≥', r'\w+‡¨´‡¨≥', r'\w+‡¨ó‡¨õ']
    plants = set()
    for pattern in plant_patterns:
        plants.update(re.findall(pattern, all_text))
    
    print(f"   ‚Ä¢ Total unique plant references: {len(plants)}")
    print(f"   ‚Ä¢ Sample plant references:")
    for plant in sorted(list(plants))[:15]:
        print(f"     - {plant}")
    
    # Disease Analysis
    print(f"\nü©∫ DISEASE & CONDITION REFERENCES")
    
    disease_patterns = [r'\w+‡¨∞‡≠ã‡¨ó', r'\w+‡¨¨‡≠ç‡≠ü‡¨æ‡¨ß‡¨ø', r'\w+‡¨ú‡≠ç‡¨¨‡¨∞']
    diseases = set()
    for pattern in disease_patterns:
        diseases.update(re.findall(pattern, all_text))
    
    print(f"   ‚Ä¢ Total unique disease references: {len(diseases)}")
    print(f"   ‚Ä¢ Sample disease references:")
    for disease in sorted(list(diseases))[:15]:
        print(f"     - {disease}")
    
    # Treatment Methods
    print(f"\nüíä TREATMENT METHODS")
    
    treatment_methods = {
        '‡¶™‡¶ø‡¶Ü‡¶á‡¶¨': 'oral consumption',
        'Àå‡¶≤‡¶ó‡§æ‡¶á‡¶¨': 'topical application', 
        '‡¶¨‡¶æ‡¶®‡ßç‡¶ß‡¶ø‡¶¨': 'bandaging/wrapping',
        '‡¶´‡ßÅ‡¶ô‡ßç‡¶ï‡¶ø‡¶¨': 'blowing/breathing on',
        '‡¶ò‡¶∑‡¶ø‡¶¨': 'rubbing/massaging',
        '‡¶ß‡ßÅ‡¶á‡¶¨': 'washing/cleaning'
    }
    
    treatment_freq = {}
    for method, description in treatment_methods.items():
        count = all_text.count(method)
        if count > 0:
            treatment_freq[f"{method} ({description})"] = count
    
    # Also check for common treatment verbs
    treatment_verbs = ['‡¨™‡¨ø‡¨Ü‡¨á‡¨¨', '‡¨≤‡¨ó‡¨æ‡¨á‡¨¨', '‡¨¨‡¨æ‡¨®‡≠ç‡¨ß‡¨ø‡¨¨', '‡¨ñ‡≠Å‡¨Ü‡¨á‡¨¨', '‡¨ò‡¨∑‡¨ø‡¨¨']
    for verb in treatment_verbs:
        count = all_text.count(verb)
        if count > 0:
            treatment_freq[verb] = count
    
    print(f"   ‚Ä¢ Treatment method frequency:")
    for method, count in sorted(treatment_freq.items(), key=lambda x: x[1], reverse=True)[:10]:
        print(f"     - {method}: {count} times")
    
    # Cultural & Spiritual Elements
    print(f"\nüïâÔ∏è CULTURAL & SPIRITUAL ELEMENTS")
    
    spiritual_terms = {
        '‡¨Æ‡¨®‡≠ç‡¨§‡≠ç‡¨∞': 'mantra/incantation',
        '‡¨Ø‡¨®‡≠ç‡¨§‡≠ç‡¨∞': 'yantra/mystical diagram',
        '‡¨™‡¨∞‡≠Ä‡¨ï‡≠ç‡¨∑‡¨ø‡¨§': 'tested/verified',
        '‡¨Ö‡¨®‡≠Å‡¨≠‡≠Ç‡¨§': 'experienced/practical',
        '‡¨¨‡¨ø‡¨∂‡≠ç‡¨µ‡¨æ‡¨∏': 'faith/belief'
    }
    
    spiritual_freq = {}
    for term, meaning in spiritual_terms.items():
        count = all_text.count(term)
        if count > 0:
            spiritual_freq[f"{term} ({meaning})"] = count
    
    print(f"   ‚Ä¢ Spiritual elements:")
    for element, count in sorted(spiritual_freq.items(), key=lambda x: x[1], reverse=True):
        print(f"     - {element}: {count} times")
    
    # Traditional Measurements
    print(f"\n‚öñÔ∏è TRADITIONAL MEASUREMENTS")
    
    measurements = ['‡¨∞‡¨§‡¨ø', '‡¨Æ‡¨æ‡¨∑', '‡¨§‡≠ã‡¨≤‡¨æ', '‡¨∏‡≠á‡¨∞', '‡¨ö‡¨æ‡¨Æ‡¨ö', '‡¨ü‡≠ã‡¨™‡¨æ']
    measurement_freq = {}
    for measure in measurements:
        count = all_text.count(measure)
        if count > 0:
            measurement_freq[measure] = count
    
    print(f"   ‚Ä¢ Measurement units:")
    for unit, count in sorted(measurement_freq.items(), key=lambda x: x[1], reverse=True):
        print(f"     - {unit}: {count} times")
    
    # Document Structure Analysis
    print(f"\nüìö DOCUMENT STRUCTURE")
    
    # Extract page numbers
    page_numbers = []
    for filename in texts.keys():
        page_match = re.search(r'_(\d+)\.txt$', filename)
        if page_match:
            page_numbers.append(int(page_match.group(1)))
    
    if page_numbers:
        print(f"   ‚Ä¢ Page range: {min(page_numbers)} - {max(page_numbers)}")
        print(f"   ‚Ä¢ Total pages: {len(page_numbers)}")
    
    # Content type classification
    content_types = {
        'index_pages': 0,
        'prescription_pages': 0,
        'introductory_pages': 0
    }
    
    for content in texts.values():
        if any(indicator in content for indicator in ['‡¨¨‡¨ø‡¨∑‡≠ü', '‡¨™‡≠É‡¨∑‡≠ç‡¨†‡¨æ']):
            content_types['index_pages'] += 1
        elif any(indicator in content for indicator in ['‡¨Ø‡≠ã‡¨ó', '‡¨î‡¨∑‡¨ß', '‡¨ö‡¨ø‡¨ï‡¨ø‡¨§‡≠ç‡¨∏‡¨æ']):
            content_types['prescription_pages'] += 1
        elif any(indicator in content for indicator in ['‡¨≠‡≠Ç‡¨Æ‡¨ø‡¨ï‡¨æ', '‡¨Ü‡¨π‡≠ç‡¨µ‡¨æ‡¨®']):
            content_types['introductory_pages'] += 1
    
    print(f"   ‚Ä¢ Content distribution:")
    for content_type, count in content_types.items():
        print(f"     - {content_type.replace('_', ' ').title()}: {count} pages")
    
    # Key Findings Summary
    print("\n" + "="*80)
    print("üéØ KEY FINDINGS & INTERPRETATION")
    print("="*80)
    
    print(f"\nüìñ DOCUMENT NATURE:")
    print(f"   ‚Ä¢ This is 'Anubhuta Jogamala' - a collection of experienced/practical medical remedies")
    print(f"   ‚Ä¢ 'Sahaja Chikitsa' means 'Simple/Easy Treatment' - accessible medical practices")
    print(f"   ‚Ä¢ Text is primarily in Odia script with traditional medical terminology")
    
    print(f"\nüåø MEDICAL APPROACH:")
    print(f"   ‚Ä¢ Heavy emphasis on plant-based medicines ({len(plants)} unique plant references)")
    print(f"   ‚Ä¢ Focus on natural, accessible ingredients from local environment")
    print(f"   ‚Ä¢ Combination of empirical knowledge with traditional practices")
    print(f"   ‚Ä¢ Covers wide range of ailments ({len(diseases)} disease types identified)")
    
    print(f"\nüèõÔ∏è CULTURAL CONTEXT:")
    print(f"   ‚Ä¢ Integration of spiritual elements (mantras, yantras) with medical practice")
    print(f"   ‚Ä¢ Use of traditional measurement systems reflecting historical practices")
    print(f"   ‚Ä¢ Emphasis on 'tested' (‡¨™‡¨∞‡≠Ä‡¨ï‡≠ç‡¨∑‡¨ø‡¨§) remedies - experiential validation")
    print(f"   ‚Ä¢ Represents preserved indigenous medical knowledge of Odisha region")
    
    print(f"\nüí° SIGNIFICANCE:")
    print(f"   ‚Ä¢ Valuable repository of traditional Odia medical knowledge")
    print(f"   ‚Ä¢ Bridge between folk medicine and documented medical practices")
    print(f"   ‚Ä¢ Reflects holistic approach combining physical and spiritual healing")
    print(f"   ‚Ä¢ Important cultural heritage document for traditional medicine research")
    
    print(f"\nüéâ Analysis completed successfully!")
    print("="*80)


if __name__ == "__main__":
    try:
        analyze_part1_texts()
    except Exception as e:
        print(f"‚ùå Analysis failed: {e}")
        import traceback
        traceback.print_exc() 