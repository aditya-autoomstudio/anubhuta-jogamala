"""
Analysis of Cleaned Anubhuta Jogamala Part 1 Texts

This script analyzes the cleaned text files to:
- Compare improvements from cleaning process
- Identify remaining OCR artifacts
- Provide comprehensive linguistic analysis
- Extract medical knowledge themes
"""

import re
from pathlib import Path
from collections import Counter
from typing import Dict, List, Set, Tuple


def analyze_cleaned_texts() -> None:
    """Analyze the cleaned text files and compare with originals."""
    
    original_dir = Path('part_1_text')
    cleaned_dir = Path('part_1_text_cleaned')
    
    print("üîç ANALYSIS OF CLEANED ANUBHUTA JOGAMALA TEXTS")
    print("="*60)
    
    # Load cleaned texts
    cleaned_texts = {}
    cleaned_files = list(cleaned_dir.glob("*.txt"))
    
    for file_path in sorted(cleaned_files):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                if content:
                    cleaned_texts[file_path.name] = content
        except Exception as e:
            print(f"Warning: Could not read {file_path.name}: {e}")
    
    if not cleaned_texts:
        print("‚ùå No cleaned text files found!")
        return
    
    print(f"‚úÖ Loaded {len(cleaned_texts)} cleaned text files")
    
    # Combine all cleaned text
    all_cleaned_text = " ".join(cleaned_texts.values())
    
    # Basic statistics
    print(f"\nüìä CLEANING RESULTS OVERVIEW")
    total_chars = len(all_cleaned_text)
    words = re.findall(r'\S+', all_cleaned_text)
    sentences = re.split(r'[‡•§\.\!\?]', all_cleaned_text)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    print(f"   ‚Ä¢ Total characters: {total_chars:,}")
    print(f"   ‚Ä¢ Total words: {len(words):,}")
    print(f"   ‚Ä¢ Total sentences: {len(sentences):,}")
    
    # Character analysis
    print(f"\nüî§ CHARACTER ANALYSIS")
    odia_chars = sum(1 for char in all_cleaned_text if '\u0B00' <= char <= '\u0B7F')
    digits = sum(1 for char in all_cleaned_text if char.isdigit())
    
    print(f"   ‚Ä¢ Odia script characters: {odia_chars:,} ({odia_chars/total_chars*100:.1f}%)")
    print(f"   ‚Ä¢ Digit characters: {digits:,} ({digits/total_chars*100:.1f}%)")
    
    # Identify remaining issues
    print(f"\n‚ö†Ô∏è  REMAINING OCR ARTIFACTS")
    
    # Find remaining problematic patterns
    artifacts = []
    
    # Mixed character sequences (likely OCR errors)
    mixed_patterns = re.findall(r'[‡¨Ö-‡¨π]+\d+[‡¨Ö-‡¨π]*', all_cleaned_text)
    if mixed_patterns:
        artifacts.extend(mixed_patterns[:10])
    
    # Standalone numbers in Odia text (likely errors)
    standalone_numbers = re.findall(r'\b\d{3,}\b', all_cleaned_text)
    if standalone_numbers:
        artifacts.extend(standalone_numbers[:10])
    
    # Unusual character combinations
    unusual_combos = re.findall(r'[‡¨Ö-‡¨π]{1}[‡≠¶-‡≠Ø]{2,}', all_cleaned_text)
    if unusual_combos:
        artifacts.extend(unusual_combos[:10])
    
    unique_artifacts = list(set(artifacts))
    print(f"   ‚Ä¢ Total artifacts found: {len(unique_artifacts)}")
    if unique_artifacts:
        print(f"   ‚Ä¢ Sample artifacts:")
        for artifact in unique_artifacts[:15]:
            print(f"     - '{artifact}'")
    
    # Medical terminology analysis
    print(f"\nüè• MEDICAL CONTENT ANALYSIS")
    
    medical_terms = {
        '‡¨∞‡≠ã‡¨ó': 'disease/illness',
        '‡¨ö‡¨ø‡¨ï‡¨ø‡¨§‡≠ç‡¨∏‡¨æ': 'treatment',
        '‡¨Ø‡≠ã‡¨ó': 'remedy/prescription',
        '‡¨™‡¨§‡≠ç‡¨∞': 'leaf',
        '‡¨∞‡¨∏': 'juice/extract',
        '‡¨ö‡≠Ç‡¨∞‡≠ç‡¨£‡≠ç‡¨£': 'powder',
        '‡¨™‡¨ø‡¨Ü‡¨á‡¨¨': 'to drink',
        '‡¨≤‡¨ó‡¨æ‡¨á‡¨¨': 'to apply',
        '‡¨Æ‡¨ø‡¨∂‡¨æ‡¨á': 'mixing',
        '‡¨Ö‡¨®‡≠Å‡¨≠‡≠Ç‡¨§': 'experienced',
        '‡¨™‡¨∞‡≠Ä‡¨ï‡≠ç‡¨∑‡¨ø‡¨§': 'tested'
    }
    
    term_freq = {}
    for term, meaning in medical_terms.items():
        count = all_cleaned_text.count(term)
        if count > 0:
            term_freq[f"{term} ({meaning})"] = count
    
    print(f"   ‚Ä¢ Medical terminology frequency:")
    for term, count in sorted(term_freq.items(), key=lambda x: x[1], reverse=True)[:10]:
        print(f"     - {term}: {count} times")
    
    # Plant and herb references
    print(f"\nüåø HERBAL MEDICINE REFERENCES")
    
    plant_patterns = [r'\w*‡¨™‡¨§‡≠ç‡¨∞', r'\w*‡¨Æ‡≠Ç‡¨≥', r'\w*‡¨´‡¨≥', r'\w*‡¨ó‡¨õ']
    plants = set()
    for pattern in plant_patterns:
        found_plants = re.findall(pattern, all_cleaned_text)
        # Filter out obvious OCR artifacts
        valid_plants = [p for p in found_plants if len(p) > 2 and not re.search(r'\d', p)]
        plants.update(valid_plants)
    
    print(f"   ‚Ä¢ Total plant references found: {len(plants)}")
    print(f"   ‚Ä¢ Sample plant names:")
    for plant in sorted(list(plants))[:15]:
        print(f"     - {plant}")
    
    # Disease references
    print(f"\nü©∫ DISEASE AND CONDITION ANALYSIS")
    
    disease_patterns = [r'\w*‡¨∞‡≠ã‡¨ó', r'\w*‡¨¨‡≠ç‡≠ü‡¨æ‡¨ß‡¨ø', r'\w*‡¨ú‡≠ç‡¨¨‡¨∞']
    diseases = set()
    for pattern in disease_patterns:
        found_diseases = re.findall(pattern, all_cleaned_text)
        # Filter out obvious OCR artifacts
        valid_diseases = [d for d in found_diseases if len(d) > 3 and not re.search(r'\d', d)]
        diseases.update(valid_diseases)
    
    print(f"   ‚Ä¢ Total disease references: {len(diseases)}")
    print(f"   ‚Ä¢ Sample diseases:")
    for disease in sorted(list(diseases))[:15]:
        print(f"     - {disease}")
    
    # Treatment methods
    print(f"\nüíä TREATMENT METHODS")
    
    treatment_verbs = ['‡¨™‡¨ø‡¨Ü‡¨á‡¨¨', '‡¨≤‡¨ó‡¨æ‡¨á‡¨¨', '‡¨ñ‡≠Å‡¨Ü‡¨á‡¨¨', '‡¨¨‡¨æ‡¨®‡≠ç‡¨ß‡¨ø‡¨¨', '‡¨ò‡¨∑‡¨ø‡¨¨', '‡¨ß‡≠ã‡¨á‡¨¨']
    treatment_freq = {}
    for verb in treatment_verbs:
        count = all_cleaned_text.count(verb)
        if count > 0:
            treatment_freq[verb] = count
    
    print(f"   ‚Ä¢ Treatment method frequency:")
    for method, count in sorted(treatment_freq.items(), key=lambda x: x[1], reverse=True):
        print(f"     - {method}: {count} times")
    
    # Measurement units
    print(f"\n‚öñÔ∏è TRADITIONAL MEASUREMENTS")
    
    measurements = ['‡¨∞‡¨§‡¶ø', '‡¨Æ‡¨æ‡¨∑', '‡¨§‡≠ã‡¨≤‡¨æ', '‡¨∏‡≠á‡¨∞', '‡¨ö‡¨æ‡¨Æ‡¨ö', '‡¨ü‡≠ã‡¨™‡¨æ', '‡¨™‡¨æ‡¨®', '‡¨Ö‡¨ß‡¨æ']
    measurement_freq = {}
    for measure in measurements:
        count = all_cleaned_text.count(measure)
        if count > 0:
            measurement_freq[measure] = count
    
    print(f"   ‚Ä¢ Measurement units found:")
    for unit, count in sorted(measurement_freq.items(), key=lambda x: x[1], reverse=True):
        print(f"     - {unit}: {count} times")
    
    # Text quality assessment
    print(f"\nüìã TEXT QUALITY ASSESSMENT")
    
    # Calculate readability metrics
    odia_word_ratio = sum(1 for word in words if any('\u0B00' <= char <= '\u0B7F' for char in word)) / len(words) if words else 0
    print(f"   ‚Ä¢ Odia word ratio: {odia_word_ratio:.1%}")
    
    # Check for common OCR error patterns
    error_patterns = [
        (r'\d+[‡¨Ö-‡¨π]+\d+', 'Number-letter-number patterns'),
        (r'[‡¨Ö-‡¨π]+\d{3,}', 'Letters followed by long numbers'),
        (r'\b\d{5,}\b', 'Very long standalone numbers'),
        (r'[‡•§\.]{2,}', 'Multiple punctuation marks'),
    ]
    
    print(f"   ‚Ä¢ OCR error patterns:")
    for pattern, description in error_patterns:
        matches = re.findall(pattern, all_cleaned_text)
        print(f"     - {description}: {len(matches)} instances")
    
    # Sample clean sentences
    print(f"\n‚úÖ SAMPLE CLEAN SENTENCES")
    
    clean_sentences = []
    for sentence in sentences[:50]:  # Check first 50 sentences
        if (len(sentence) > 20 and 
            sum(1 for char in sentence if '\u0B00' <= char <= '\u0B7F') / len(sentence) > 0.7 and
            not re.search(r'\d{3,}', sentence)):
            clean_sentences.append(sentence)
        if len(clean_sentences) >= 5:
            break
    
    for i, sentence in enumerate(clean_sentences, 1):
        print(f"   {i}. {sentence[:100]}...")
    
    # Recommendations
    print(f"\nüí° RECOMMENDATIONS FOR FURTHER IMPROVEMENT")
    print(f"   ‚Ä¢ Remove remaining number artifacts: {len(set(standalone_numbers))} instances")
    print(f"   ‚Ä¢ Fix mixed character sequences: {len(set(mixed_patterns))} instances") 
    print(f"   ‚Ä¢ Consider manual review of medical terminology")
    print(f"   ‚Ä¢ Verify plant and disease name accuracy")
    print(f"   ‚Ä¢ Cross-reference with medical dictionaries")
    
    print(f"\nüéâ Analysis completed!")
    print("="*60)


if __name__ == "__main__":
    try:
        analyze_cleaned_texts()
    except Exception as e:
        print(f"‚ùå Analysis failed: {e}")
        import traceback
        traceback.print_exc() 